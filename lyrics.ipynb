{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#!git clone https://github.com/huggingface/transformers.git#\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install transformers==\"4.0.0\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.text.all import *\nimport torch\nfrom transformers import GPT2TokenizerFast, GPT2LMHeadModel\nimport pandas as pd\nimport glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_weights = 'gpt2'\ntokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\nmodel = GPT2LMHeadModel.from_pretrained(pretrained_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = tokenizer.encode('This is an example of text, and')\nt = torch.LongTensor(ids)[None]\npreds = model.generate(t)\ntokenizer.decode(preds[0].numpy())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('/kaggle/input/dataforlyrics/21pilots/train.csv', encoding=\"utf8\", errors='ignore') as f:\n    train=pd.Series(f,index=None)\nwith open('/kaggle/input/dataforlyrics/21pilots/valid.csv', encoding=\"utf8\", errors='ignore') as f:\n    valid=pd.Series(f,index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,valid.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.dropna()\nvalid=valid.dropna()\ntrain.head(),valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_texts = np.concatenate([train.values, valid.values])\n\nall_texts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize(text):\n    toks = tokenizer.tokenize(text)\n    return tensor(tokenizer.convert_tokens_to_ids(toks))\n\ntokenized = [tokenize(t) for t in progress_bar(all_texts)]\n\nclass TransformersTokenizer(Transform):\n    def __init__(self, tokenizer): self.tokenizer = tokenizer\n    def encodes(self, x): \n        return x if isinstance(x, Tensor) else tokenize(x)\n        \n    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs,sl = 4,256\nsplits = [range_of(train), list(range(len(train), len(all_texts)))]\ntls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\ndls = tls.dataloaders(bs=bs, seq_len=sl)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls.show_batch(max_n=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DropOutput(Callback):\n    def after_pred(self): self.learn.pred = self.pred[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.validate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.path=Path('/')\nlearn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(20, 1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_loss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prompt = \"\\n uh \"\nprompt_ids = tokenizer.encode(prompt)\ninp = tensor(prompt_ids)[None].cuda()\npreds = learn.model.generate(inp,\n                             do_sample=True, \n                             max_length=90,\n                             min_length=5,\n                             top_k=40,\n                             num_return_sequences=1)\ntokenizer.decode(preds[0].cpu().tolist())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.export('/kaggle/working/21pilots.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#device=torch.device('cpu:0')\n#learn.model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}